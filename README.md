<h1>Сервис дедубликации сообщений.</h1>

Сервис дедубликации сообщений, который в режиме реального времени вычитывает сообщения из топика `Kafka`, 
применяет правила дедубликации из `PostgreSQL`, используя для хранения ключей дедубликации `Redis`, и отправляет сообщения, удовлетворяющие условиям дедубликации, в выходной топик `Kafka`.
Правила фильтрации также могут обновляться в режиме реального времени пользователями сервиса. Несколько правил фильтрации объединяются в один ключ дедубликации. Например в одном правиле указан field_name = "name", а в другом field_name = "age", 
значит дублем будут считаться только сообщения у которых совпадает "name" и "age". В общей картине - сервис дедубликации должен читать сообщения из топика Kafka, куда отправляет свои сообщения сервис фильтрации

Сервис вычитывает конфигурации из `application.conf`.

Сервис раз в заданное время (параметр `updateIntervalSec`) проверяет данные в `postgreSQL` и обновляет правила фильтрации при необходимости.

Сервис в режиме реального времени читает сообщения из `Kafka` (`json`) и отправляет сообщения в `Kafka` в том же виде (`json`), но только те, которые удовлетворяют правилам дедубликации.

Для соединения с БД используется connection pool `HikariCP`.

Для работы с БД (запросы) используется библиотека `JOOQ`.

Для хранения состояния ключей - используется `Redis`.

Для работы с конфигурациями (`application.conf`) - `typesafe config`.

Для логирования используется библиотека `Sl4j`

![Сервис дедубликации](https://user-images.githubusercontent.com/3996014/233505915-7b3bb434-93b0-4df5-9e0f-82935aee99f4.png)